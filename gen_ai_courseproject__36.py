# -*- coding: utf-8 -*-
"""GEN AI_COURSEPROJECT__36.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HvOk1jw9ApRGXVNhuE_Gfi6bNExNP_fZ
"""

import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Conv2DTranspose, BatchNormalization, ReLU, Reshape
from tensorflow.keras.models import Model
import numpy as np
import pandas as pd
import cv2
import librosa
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.metrics import accuracy_score, precision_score, mean_squared_error, f1_score

# ðŸ”¹ Load Dataset (Modify path as needed)
df = pd.read_csv("/movies_youtube_sentiments.csv")

# ðŸ”¹ Handle Missing Values & Convert Everything to String
df.fillna("Unknown", inplace=True)

# ðŸ”¹ Combine relevant columns for better text input
df['combined_text'] = df[['name', 'genre', 'director', 'writer', 'star']].astype(str).agg(' '.join, axis=1)

def preprocess_text(texts, vocab_size=5000, max_length=50):
    """Tokenize and pad text input"""
    tokenizer = Tokenizer(num_words=vocab_size, oov_token="<OOV>")
    tokenizer.fit_on_texts(texts)  # The input 'texts' is already a list
    sequences = tokenizer.texts_to_sequences(texts)
    padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')
    return padded_sequences, tokenizer

def extract_video_features(video_path, frame_rate=1):
    """Extract keyframes from video at a specified frame rate"""
    cap = cv2.VideoCapture(video_path)
    frames = []
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        frames.append(cv2.resize(frame, (64, 64)))  # Resize for model input
    cap.release()
    return np.array(frames)

def extract_audio_features(audio_path, sr=22050, n_mfcc=13):
    """Extract MFCC features from audio"""
    y, sr = librosa.load(audio_path, sr=sr)
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)
    return np.mean(mfcc, axis=1)

def build_text_encoder(vocab_size, embedding_dim=128, lstm_units=256):
    """Text Encoder for user input (Genre, Storyline, etc.)"""
    text_input = Input(shape=(None,))  # Input is sequence of word indices
    x = Embedding(vocab_size, embedding_dim)(text_input)
    x = LSTM(lstm_units)(x)
    return Model(text_input, x, name="Text_Encoder")

def build_video_generator(latent_dim=256):
    """Video Generator using GAN approach"""
    noise_input = Input(shape=(latent_dim,))
    x = Dense(8*8*512, activation='relu')(noise_input)
    x = Reshape((8, 8, 512))(x)
    x = Conv2DTranspose(256, kernel_size=3, strides=2, padding='same')(x) # Output: (16, 16, 256)
    x = BatchNormalization()(x)
    x = ReLU()(x)
    x = Conv2DTranspose(128, kernel_size=3, strides=2, padding='same')(x) # Output: (32, 32, 128)
    x = BatchNormalization()(x)
    x = ReLU()(x)
    x = Conv2DTranspose(64, kernel_size=3, strides=2, padding='same')(x)  # Output: (64, 64, 64)
    x = BatchNormalization()(x)
    x = ReLU()(x)
    # Changed strides to 1 to get (64, 64, 3) output
    video_output = Conv2DTranspose(3, kernel_size=3, strides=1, padding='same', activation='tanh')(x)
    return Model(noise_input, video_output, name="Video_Generator")

def build_movie_generation_model(vocab_size, latent_dim=256):
    """Complete Model: Combines Text Input and Video Generation"""
    text_encoder = build_text_encoder(vocab_size)
    video_generator = build_video_generator(latent_dim)

    user_input = Input(shape=(None,))
    text_features = text_encoder(user_input)
    generated_video = video_generator(text_features)

    return Model(user_input, generated_video, name="Movie_Generation_Model")

# ðŸ”¹ Define Model Parameters
vocab_size = 5000  # Adjust based on dataset
latent_dim = 256
movie_model = build_movie_generation_model(vocab_size, latent_dim)
movie_model.summary()

# ðŸ”¹ Preprocess dataset with updated 'combined_text'
processed_text, tokenizer = preprocess_text(df['combined_text'])
df['processed_text'] = processed_text.tolist() # Convert 2D array to a list of lists

print("âœ… Data preprocessing complete. Ready for training!")

# ðŸ”¹ Example: Generate fake labels for training (Modify based on real data)
X_train = np.array(df['processed_text'].tolist()) # Convert to NumPy array with correct dtype
y_train = np.random.rand(len(X_train), 64, 64, 3)  # Dummy video output data

# ðŸ”¹ Train the Model
movie_model.compile(optimizer='adam', loss='mse')
movie_model.fit(X_train, y_train, epochs=5, batch_size=16)

print("âœ… Model training complete!")

# ðŸ”¹ Evaluation: Compute Metrics
y_pred = movie_model.predict(X_train)

# Flatten for comparison
y_train_flat = y_train.flatten()
y_pred_flat = y_pred.flatten()

accuracy = accuracy_score(y_train_flat.round(), y_pred_flat.round())
precision = precision_score(y_train_flat.round(), y_pred_flat.round(), average='macro')
mse = mean_squared_error(y_train_flat, y_pred_flat)
f1 = f1_score(y_train_flat.round(), y_pred_flat.round(), average='macro')

print(f"ðŸ”¹ Accuracy: {accuracy}")
print(f"ðŸ”¹ Precision: {precision}")
print(f"ðŸ”¹ MSE: {mse}")
print(f"ðŸ”¹ F1 Score: {f1}")

print("ðŸŽ¬ AI Movie Trailer Generation Pipeline Complete! ðŸš€")

def build_optimized_video_generator(latent_dim=256):
    noise_input = Input(shape=(latent_dim,))
    x = Dense(8*8*512, activation='relu')(noise_input)
    x = Reshape((8, 8, 512))(x)
    x = Conv2DTranspose(256, kernel_size=3, strides=2, padding='same')(x)
    x = BatchNormalization()(x)
    x = ReLU()(x)
    x = Dropout(0.3)(x)  # Prevent Overfitting
    x = Conv2DTranspose(128, kernel_size=3, strides=2, padding='same')(x)
    x = BatchNormalization()(x)
    x = ReLU()(x)
    x = Dropout(0.3)(x)
    x = Conv2DTranspose(64, kernel_size=3, strides=2, padding='same')(x)
    x = BatchNormalization()(x)
    x = ReLU()(x)
    # Changed strides to 1 to match the target data shape (64, 64, 3)
    video_output = Conv2DTranspose(3, kernel_size=3, strides=1, padding='same', activation='tanh')(x)
    return Model(noise_input, video_output, name="Optimized_Video_Generator")

# ðŸ”¹ Update Movie Generation Model
def build_optimized_movie_model(vocab_size, latent_dim=256):
    text_encoder = build_text_encoder(vocab_size)
    video_generator = build_optimized_video_generator(latent_dim)

    user_input = Input(shape=(None,))
    text_features = text_encoder(user_input)
    generated_video = video_generator(text_features)

    return Model(user_input, generated_video, name="Optimized_Movie_Generation_Model")

# ðŸ”¹ Train Optimized Model
optimized_movie_model = build_optimized_movie_model(vocab_size)
optimized_movie_model.compile(optimizer=Adam(learning_rate=0.0001, clipnorm=1.0), loss='mse')  # Gradient Clipping
optimized_movie_model.fit(X_train, y_train, epochs=10, batch_size=16)

print("âœ… Model Optimization Complete!")

def generate_movie_trailer(user_input_text):
    # ðŸ”¹ Convert user input into model-friendly format
    user_sequence, _ = preprocess_text([user_input_text])

    # ðŸ”¹ Generate video using AI model
    generated_video = optimized_movie_model.predict(user_sequence)

    # ðŸ”¹ Save the generated video
    video_filename = "generated_trailer.mp4"
    out = cv2.VideoWriter(video_filename, cv2.VideoWriter_fourcc(*'mp4v'), 10, (64, 64))

    for frame in generated_video[0]:
        frame = (frame * 255).astype(np.uint8)  # Convert to valid image format
        out.write(frame)

    out.release()

    print(f"ðŸŽ¬ Trailer Generated! Saved as {video_filename}")

# ðŸ”¹ Example Usage
user_input = "A sci-fi thriller about an AI revolution in 2099."
generate_movie_trailer(user_input)

from flask import Flask, request, jsonify

app = Flask(__name__)

@app.route('/generate_trailer', methods=['POST'])
def generate_trailer():
    data = request.get_json()
    user_input = data.get("description", "")

    if not user_input:
        return jsonify({"error": "Please provide a movie description"}), 400

    generate_movie_trailer(user_input)

    return jsonify({"message": "Trailer generated!", "file": "generated_trailer.mp4"})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)